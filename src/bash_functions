~/.secrets/build_souper_secrets.sh
source ~/.secrets/functions

# scl: "get_color" -- Set terminal color
scl() {
    local color_value=$1

    # Map user-friendly color names to RGB values
    case "$color_value" in
        orange) color_value='rgb530' ;;
        maroon) color_value='rgb320' ;;
        olive) color_value='rgb330' ;;
        navy) color_value='rgb003' ;;
        teal) color_value='rgb033' ;;
        lime) color_value='rgb250' ;;
        coral) color_value='rgb550' ;;
        salmon) color_value='rgb540' ;;
        beige) color_value='rgb542' ;;
        mint) color_value='rgb253' ;;
        lavender) color_value='rgb432' ;;
        plum) color_value='rgb302' ;;
        indigo) color_value='rgb104' ;;
        gold) color_value='rgb530' ;;
        pink) color_value='rgb532' ;;
        tan) color_value='rgb531' ;;
        coffee) color_value='rgb321' ;;
        chocolate) color_value='rgb320' ;;
        azure) color_value='rgb156' ;;
        silver) color_value='rgb555' ;;
        rand)
            # Generate random RGB values between 0-5
            local r=$((RANDOM % 6))
            local g=$((RANDOM % 6))
            local b=$((RANDOM % 6))
            color_value="rgb$r$g$b"
            ;;
    esac

    case "$color_value" in
        black)    tput setaf 0 ;;
        red)      tput setaf 1 ;;
        green)    tput setaf 2 ;;
        yellow)   tput setaf 3 ;;
        blue)     tput setaf 4 ;;
        magenta)  tput setaf 5 ;;
        cyan)     tput setaf 6 ;;
        white)    tput setaf 7 ;;
        rgb[0-5][0-5][0-5])
            local r="${color_value:3:1}"
            local g="${color_value:4:1}"
            local b="${color_value:5:1}"
            local code=$((16 + (36 * r) + (6 * g) + b))
            tput setaf $code ;;
        gray[0-9]|gray1[0-9]|gray2[0-3])
            local gray_value="${color_value:4}"
            local code=$((232 + gray_value))
            tput setaf $code ;;
        *)
            echo "Unknown color: $color_value" >&2; return 1 ;;
    esac
}

# ctxt: color text
ctxt(){
    python $BASHER/src/py_scripts/ctxt.py $@
}

# ftxt: file text colored
ftxt() {
    FILE=$1
    OPTS=$2
    READ_FROM_FILE=${3:-""}
    
    # Check if -f (file read) flag is present, then prepend it to the file argument
    if [ "$READ_FROM_FILE" = "-f" ]; then
        FILE_ARG="-f $FILE"
    else
        FILE_ARG="$FILE"
    fi
    
    # Now call ctxt with the file argument and the contents of the options file
    ctxt $FILE_ARG $(cat "$OPTS")
}

# cecho_legacy: colored echo legacy before scl function
cecho_legacy() {
    local no_newline=0
    local color_value

    # Check for -n option
    if [ "$1" = "-n" ]; then
        no_newline=1
        shift
    fi

    # Check for --color= option
    if [[ "$1" =~ ^--color= ]]; then
        color_value="${1#*=}"  # Extract the value after the '=' sign
        shift
    else
        color_value="red"
    fi

    local text="$@"
    
    case "$color_value" in
        black)    tput setaf 0 ;;
        red)      tput setaf 1 ;;
        green)    tput setaf 2 ;;
        yellow)   tput setaf 3 ;;
        blue)     tput setaf 4 ;;
        magenta)  tput setaf 5 ;;
        cyan)     tput setaf 6 ;;
        white)    tput setaf 7 ;;
        rgb[0-5]_[0-5]_[0-5])
            local r="${color_value:3:1}"
            local g="${color_value:5:1}"
            local b="${color_value:7:1}"
            local code=$((16 + (36 * r) + (6 * g) + b))
            tput setaf $code ;;
        gray[0-9]|gray1[0-9]|gray2[0-3])
            local gray_value="${color_value:4}"
            local code=$((232 + gray_value))
            tput setaf $code ;;
        *)
            echo "Unknown color: $color_value" >&2; return 1 ;;
    esac

    if [ $no_newline -eq 1 ]; then
        echo -n "$text"
    else
        echo "$text"
    fi

    tput sgr0  # Reset text attributes to normal without clearing screen.
}

# see_fonts: see fonts
see_fonts(){
    fc-list | cut -f2 -d':' | sort -u
}

# set_var: set environment variable
set_var() {
    if [ "$#" -ne 1 ]; then
        echo "Usage: echo VAR_VALUE | set_var VAR_NAME"
        return 1
    fi

    read -r VAR_CONTENT
    eval "export $1=\"$VAR_CONTENT\""
}

# prepend_env_var: conda environment helpers
prepend_env_var() {
    # Check if the environment variable is already set
    if [ -z "${!1}" ]; then
        # If not, set the environment variable to the new value without a trailing colon
        export $1=$2
    else
        # If yes, store the old value and prepend the new value with a colon separator
        export OLD_$1=${!1}
        export $1=$2:${!1}
    fi
}

# revert_env_var: conda environment helpers
revert_env_var() {
    local old_var="OLD_$1"
    eval "export $1=\"\${$old_var}\""

    # Unset the old value
    unset OLD_$1
}

# start_ssh: start ssh agent
start_ssh(){
    eval "$(ssh-agent -s)"
}

# ssh_add_all: add all ssh keys
ssh_add_all(){
    ssh-add $(find ~/.ssh -type f -name 'id_*' ! -name '*.pub')
}

# matlab: start matlab
matlab(){
    LAST_DIR=$(pwd)
    cd ~/MATLAB/Source
    ~/MATLAB/R2023a/bin/matlab &
    cd $LAST_DIR
}

# pfs: print file contents recursively
pfs() {
  local dir=$1
  local pattern=$2
  local regex=$3  # get the function's third argument
  find "$dir" -type f -name "$pattern" -print0 | while IFS= read -r -d $'\0' file; do
    echo "$file"
    echo "$(printf '%.0s*' {1..80})"
    # If regex is provided, use it to filter file contents
    if [[ -n "$regex" ]]; then
      grep -E "$regex" "$file" || echo "No match found for regex '$regex'"
    else
      cat "$file"
    fi
    echo "$(printf '%.0s*' {1..80})"
  done
}

# grb: git rebase
grb() {
    find . -name '*.orig' -delete
    find . -name '*LOCAL*' -delete
    find . -name '*REMOTE*' -delete
    find . -name '*BACKUP*' -delete
    find . -name '*.~HEAD~' -delete
    find . -name '*BASE*' -delete
}

# kkp: kill process by port
kkp(){
    TMP=$(lsof -i :$1 | awk '{print $2}' | sed -n '2p')
    echo "kill $TMP"
    kill $TMP
}

# vit: vim with terminal
vit(){
    vim -c "vertical terminal" $1
}

# rclr: random color
rclr(){
    red_channel=$((RANDOM % 6))
    green_channel=$((RANDOM % 6))
    blue_channel=$((RANDOM % 6))
    color_value="rgb$red_channel$green_channel$blue_channel"
    echo $color_value
}

# gpu_mem: see gpu memory
gpu_mem() {
  my_color=${1:-$(rclr)}
  timestamp=${2:-0}
  
  ctxt "$timestamp sec    " -l -c $my_color -e
  echo -n "    "
  nvidia-smi --query-gpu=index,memory.used --format=csv,nounits,noheader | while IFS=", " read -r index memory; do
    memory_gb=$(awk "BEGIN {printf \"%.2f\",${memory}/1024}")
    ctxt -l "    GPU #${index}: ${memory_gb} GB" -c $my_color -e
    echo -n "    "
  done
  echo 
}

# mgpu: monitor gpu
mgpu(){
    iterations=${3:-1000}
    sleep_time=${4:-3}
    c1=${1:-$(rclr)}
    c2=${2:-$(rclr)}
    ctxt "Color 1: $c1" -l -c $c1 -e
    echo -n "    "
    ctxt "Color 2: $c2" -l -c $c2 
    for ((i=0; i<iterations; i++)); do
        if ((i % 2 == 0)); then
            gpu_mem "$c1" $((i * sleep_time))
        else
            gpu_mem "$c2" $((i * sleep_time))
        fi
        sleep $sleep_time
    done
}

# jail_list: list all banned IPs
jail_list(){
    JAIL=${1:-"sshd"}
    JAIL_LIST=$(sudo fail2ban-client status $JAIL | grep "Banned")
    JAIL_LIST=$(echo $JAIL_LIST | awk '{for (i=5; i<=NF; i++) printf $i " "; print ""}')
    echo $JAIL_LIST | tr ' ' '\n'
}

# ban_ip: ban an IP
ban_ip(){
    IP=$1
    JAIL=${2:-"sshd"}
    sudo fail2ban-client set $JAIL banip $IP
}

# unban_ip: unban an IP
unban_ip(){
    IP=$1
    JAIL=${2:-"sshd"}
    sudo fail2ban-client set $JAIL unbanip $IP
}

# unban_ip_regex: unban all IPs matching a regex
unban_ip_regex(){
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}
    local JAIL=${2:-"sshd"}
    local JAIL_LIST=$(jail_list $JAIL)
    JAIL_LIST=$(echo $JAIL_LIST | tr ' ' '\n' | grep $REGEX)
    for IP in $JAIL_LIST; do
        echo "Unbanning $IP"
        unban_ip $IP $JAIL 2> /dev/null > /dev/null
    done
}

# unban_first: unban the first IP
unban_first(){
    JAIL=${1:-"sshd"}
    unban_ip $(sudo fail2ban-client status $JAIL | grep "Banned" | awk '{print $5}')
}


# cdmr: change directory to most recent
cdmr(){
    DIR=${1:-$CDMR_DEFAULT}
    cd $DIR/$(ls $DIR -tr | tail -n 1)
}

# ensure_ssh_agent: ensure ssh agent is running
ensure_ssh_agent() {
    # Find all agent sockets based on the file structure
    AGENT_SOCKETS=$(find /tmp/ssh-* -type d -exec find {} -name "agent.*" \;)

    # Convert AGENT_SOCKETS into an array
    SOCKET_ARRAY=($AGENT_SOCKETS)

    # If there's no active agent socket
    if [[ ${#SOCKET_ARRAY[@]} -eq 0 ]]; then
        echo "No active SSH agent socket found. Starting one now..."
        eval $(ssh-agent -s)
        echo "SSH agent started with PID $SSH_AGENT_PID"
        
    # If there's exactly one agent socket
    elif [[ ${#SOCKET_ARRAY[@]} -eq 1 ]]; then
        export SSH_AUTH_SOCK=${SOCKET_ARRAY[0]}
        echo "Bound to existing SSH agent at $SSH_AUTH_SOCK"
        
    # If there's more than one agent socket
    else
        echo "Warning: Multiple SSH agent sockets found (${#SOCKET_ARRAY[@]} sockets)."
        echo "To kill all active ssh-agents and start afresh, run:"
        echo "pkill -u $USER ssh-agent && ensure_ssh_agent"
    fi
    ssh_add_all
}

# bpushm: basher push main
bpushm() {
    PREV=$(pwd)
    cd $BASHER
    gau
    gcm $1
    gp
    cd $PREV
}

# bpush: basher push
bpush() {
    PREV=$(pwd)
    cde $BASHER
    echo $(pwd)
    gau
    gc
    gp
    cd $PREV
}

# bpull: basher pull
bpull(){
    PREV=$(pwd)
    cd $BASHER
    git pull
    cd $PREV
}

# dwre: deepwave reinstall and test
dwre(){
    RETEST=${1:-0}
    REDOWNLOAD_DATA=${2:-0}
    CURR_PATH=$(pwd)
    cdi
    ./reinstall_and_test.sh $RETEST $REDOWNLOAD_DATA
    cd $CURR_PATH
}

# tyc: remove files from path matching regex
tyc(){
    CURR_PATH=${2:-.}
    REGEX=${1:-"AnExpressionThatWillNeverMatchAnythingHOORAH.NOPE"}

    if [[ "$REGEX" == ".*" || "$REGEX" == "*" ]]; then
        echo "Cannot clean everything"
        return
    fi

    RESULTS=$(find . -type f -name "$REGEX")
    echo $RESULTS
    find . -type f -name "$REGEX" -delete
}

# sfunc: source bash functions
sfunc(){
    source ~/.bash_functions
}

# salias: source bash aliases
salias(){
    source ~/.bash_aliases
}

# svars: source bash environment variables
svars(){
    source ~/.bash_env_vars
}

# senv: source bash environment
senv(){
    source ~/.bash_env
}

# shelp: source bash helpers
shelp(){
    source ~/.bash_source_helpers
} 

# codeo: open files in vscode
codeo(){
    PATTERN=${1:-"*.jpg"}
    CURR_PATH=${2:-.}
    LIMIT=${3:-3}
    RES=$(find . -type f -name "$PATTERN")
    NUM_RES=$(echo $RES | wc -l)
    if [[ $NUM_RES -eq 0 ]]; then
        echo "No results found"
        return
    fi
    if [[ $NUM_RES -gt $LIMIT ]]; then
        echo "$NUM_RES results found. Opening only first $LIMIT"
        RES=$(echo $RES | head -n $LIMIT)
        return
    fi
    echo "Opening following files"
    echo $RES
    code $RES
}

# gsg: see unstaged git files
gsg(){
    KEEP=${1:-modified}
    OMIT=${2:-.gitkeep}
    git status -uno | grep -E "$KEEP" | grep -vE "$OMIT" | awk '{print $2}'
}

# gag: add git files matching gsg convention
gag(){
    ga $(gsg $1 $2)
}

# ge: "git everything" - gau; gc; gp
ge(){
    gau
    gc
    gp
}

# gem: "git everything message" - gau; gcm $1; gp
gem(){
    gau
    gcm $1
    gp
}

# geg: "git everything gsg" - gau; gag $1 $2; gc; gp
geg(){
    gag $1 $2
    gc
    gp
}

# ufw_bak: backup ufw rules
ufw_bak(){
    mkdir -p ~/.backups/ufw
    if [ -f /etc/ufw/user.rules ]; then
        sudo cp /etc/ufw/user.rules ~/.backups/ufw/user.rules
        if [ $? -eq 0 ]; then
            echo "Backup successful."
        else
            echo "Backup failed."
        fi
    else
        echo "/etc/ufw/user.rules does not exist."
    fi
}   

# ufw_bak2: backup ufw rules
ufw_bak2(){
    if [ -f ~/.backups/ufw/user.rules ]; then
        sudo cp ~/.backups/ufw/user.rules ~/.backups/ufw/user.rules.bak
        if [ $? -eq 0 ]; then
            echo "Double backup successful."
        else
            echo "Double backup failed."
        fi
    else
        echo "~/.backups/ufw/user.rules does not exist."
    fi
}

# ufw_restore: restore ufw rules
ufw_restore(){
    ufw_bak2
    if [ -f ~/.backups/ufw/user.rules ]; then
        sudo cp ~/.backups/ufw/user.rules /etc/ufw/user.rules
        if [ $? -eq 0 ]; then
            sudo ufw reload
            echo "Restore and reload successful."
        else
            echo "Restore failed."
        fi
    else
        echo "~/.backups/ufw/user.rules does not exist."
    fi
}

# ufw_swap_bak: swap ufw rules with backup
ufw_swap_bak(){
    # Create a temporary backup of the current 'user.rules'
    sudo cp ~/.backups/ufw/user.rules ~/.backups/tmp.rules || { echo "Failed to create temp backup"; return 1; }

    # Swap 'user.rules' and 'user.rules.bak'
    sudo mv ~/.backups/ufw/user.rules.bak ~/.backups/ufw/user.rules || { echo "Failed to swap backups"; return 1; }

    # Replace the backup with the temporary file
    sudo mv ~/.backups/tmp.rules ~/.backups/ufw/user.rules.bak || { echo "Failed to finalize swap"; return 1; }
}

# ufw_fsd_legacy: find and delete ufw rules containing SCALPEL_DENY
ufw_fsd_legacy() {
    # Find the first rule with "SCALPEL_DENY", get its number and IP
    local rule_info=$(sudo ufw status numbered | grep "SCALPEL_DENY" | awk 'NR==1{print $2, $(NF-2)}' | tr -d '[]')
    local rule_num=$(echo $rule_info | awk '{print $1}')
    local from_ip=$(echo $rule_info | awk '{print $2}')

    # Check if a rule was found
    if [[ -z "$rule_num" ]]; then
        echo "ufw_fsd found no SCALPEL_DENY directives."
        return 1
    else
        # Delete the rule; use --force to bypass confirmation
        sudo ufw --force delete $rule_num
        echo "Deleted rule number $rule_num for IP $from_ip containing SCALPEL_DENY."
    fi
}

# ufw_fsd: find and delete ufw rules containing SCALPEL_DENY
ufw_fsd(){
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}
    local rule_info=$(sudo ufw status numbered | grep "SCALPEL_DENY")
    rule_info=$(echo "$rule_info" | grep "$REGEX") 
    rule_info=$(echo "$rule_info" | sed 's/\[[ ]*\([0-9][0-9]*\)\]/\1/g')
    rule_info=$(echo "$rule_info" | awk '{print $1,$5}')
    local rule_num=$(echo $rule_info | awk '{print $1}')
    local from_ip=$(echo $rule_info | awk '{print $2}')

    # Check if a rule was found
    if [[ -z "$rule_num" ]]; then
        echo "ufw_fsd found no SCALPEL_DENY directives matching REGEX='$REGEX'."
        return 1
    else
        # Delete the rule; use --force to bypass confirmation
        sudo ufw --force delete $rule_num
        echo "Deleted rule number $rule_num for IP $from_ip containing SCALPEL_DENY."
        return $from_ip
    fi
}

# ufw_all_scalpel: find and delete all ufw rules containing SCALPEL_DENY
ufw_all_scalpel() {
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}
    # Run the backup function at the beginning
    ufw_bak2
    ufw_bak

    # Loop until ufw_fsd returns 1
    while true; do
        ufw_fsd $REGEX
        if [[ $? -eq 1 ]]; then
            echo "All SCALPEL_DENY directives purged. To restore previous config, run ufw_restore."
            return 0
        fi
    done
}

# ufw_all_scalpel_unban: find and delete all ufw rules containing SCALPEL_DENY
ufw_all_scalpel_unban() {
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}

    ufw_all_scalpel $REGEX
    unban_ip_regex $REGEX
}

# unr_alias: unravel an alias
unr_alias() {
    alias $1 2> /dev/null | sed -E "s/alias $1='(.*)'/\1/;s/\$[0-9]\{1,\}//g" | envsubst
}

# atrm_all: remove all at jobs
atrm_all() {
    num_calls=$(atq | wc -l)

    for ((i=1; i<=num_calls; i++)); do
      atrm $(atq | awk '{print $1}' | head -n 1)
    done
}

# jbr: "jupyter bind remote"
jbr(){
    REMOTE_DOMAIN=$1
    HOST_PORT=${2:-8889}
    REMOTE_PORT=${3:-8888}
    ssh -N -f -L localhost:$HOST_PORT:localhost:$REMOTE_PORT $REMOTE_DOMAIN
}

# jmr: "jupyter make remote"
jmr(){
    PORT=${1:-8888}
    MODE=${2:-"lab"}
    jupyter $MODE --no-browser --port=$PORT
}

# gcp: "git clean preview"
gcp() {
    git clean -ndfx
}

# exp: "expand environment variables"
exp(){
    eval echo $1
}

# cde: "cd expand"
cde() {
    cd "$(exp $1)"
}

# ups: "update setup"
ups(){
    local TMP_BASHER=$(exp $BASHER)
    python $TMP_BASHER/src/py_scripts/ups.py
}

# gmu: "git merge up"
gmu(){
    TARGET=${1:-"main"}
    CURR=$(git rev-parse --abbrev-ref HEAD)
    git pull
    git checkout $TARGET
    git pull
    git merge $CURR
    git push
    git checkout $CURR
}

# gmd: "git merge down"
gmd(){
    SRC=${1:-"main"}
    CURR=$(git rev-parse --abbrev-ref HEAD)
    git pull
    git checkout $SRC
    git pull
    git checkout $CURR
    git merge $SRC
}

# no_suspend: prevent suspend
no_suspend(){
    gnome-session-inhibit --inhibit-only --inhibit "idle:suspend" &
}

# cver: "check version"
cver(){
    cat setup.py | grep "version"
}

# cemu: "CI git-everything merge up"
cemu(){
    ups; gem $1; gmu
}

# rpython "rich python" -- deprecated
rpython(){
    python $BASHER/src/py_scripts/rich_python.py $@
}

# cols: columnize output
cols(){
    python $BASHER/src/py_scripts/cols.py $@
}

# user_funcs_cols: see user functions
user_funcs_cols(){
    COLS=${1:-5}
    BASH_FUNCS=$(cat "$HOME/.bash_functions")
    PLATFORM_FUNCS=$(cat "$HOME/.platform/functions")
    grep_regex='.*()[ ]*{'
    sed_regex='s/\(.*\)[ ]*([ ]*)[ ]*\{/\1/'
    FIRST=$(echo "$BASH_FUNCS" | grep -E $grep_regex | sed -E "$sed_regex" | grep -v "^ " | grep -v "^#")
    SECOND=$(echo "$PLATFORM_FUNCS" | grep -E $grep_regex | sed -E "$sed_regex" | grep -v "^ " | grep -v "^#")
    TOTAL=$(echo "$FIRST\n$SECOND" | sort | uniq)
    cols -c $COLS "$(echo $TOTAL)"
}

# user_funcs: see user functions
user_funcs(){
    cat "$HOME/.bash_functions" "$HOME/.platform/functions" | grep "^# " | sed 's/# //' | sort
}

# undoc_funcs: see undocumented functions
undoc_funcs(){
    user_funcs | awk '{print $1}' | sed 's/://' > /tmp/user_funcs.txt
    user_funcs_cols 1 > /tmp/user_funcs_cols.txt
    code --diff /tmp/user_funcs.txt /tmp/user_funcs_cols.txt
}

# ufd: "user functions docs"
ufd(){
    grep_regex='^# \(.*\): \(.*\)'
    sed_regex='s/^# \(.*\)/\1/'
    awk_cmd='{printf "%-30s %s\n", $1, $2}'
    echo 'USER FUNCTIONS'
    grep $grep_regex "$HOME/.bash_functions" | sort | uniq | sed $sed_regex | awk -F':' "$awk_cmd"
    echo; echo; echo; echo 'PLATFORM FUNCTIONS'
    grep $grep_regex "$HOME/.platform/functions" | sort | uniq | sed $sed_regex | awk -F':' "$awk_cmd"
}

# all_git: run a git command in all git repos
all_git(){
    CMD=$1
    ROOT=${2:-$REPO}
    directories=$(find "$ROOT" -type d -name ".git" -exec dirname {} \;)

    # Iterate over each directory
    for dir in $directories; do
        cd "$dir" || continue  # Change to the directory, or skip to the next iteration if cd fails
        eval "$CMD"  # Pull the latest changes
    done
}

# agfetch: fetch all git repos
agfetch(){
    all_git '
        git fetch origin;
        res=$(git log HEAD..origin/HEAD --oneline);
        if [[ -z "$res" ]]; then
            echo "$dir -- ALREADY UP TO DATE";
        else
            echo "$dir -- MERGEABLE: Run git merge origin to update";
        fi
    ' "$1"
}

# agpull: pull all git repos
agpull(){
    all_git 'git pull' $1
}

# agsee: see all git repos
agsee(){
    all_git 'echo "$dir"' $1
}

# agmo: merge all git repos
agmo(){
    all_git 'git merge origin' $1
}

# create_worktrees: create worktrees for all remote branches
create_worktrees() {
    # Get the absolute path to the root of the repo
    REPO_ROOT=$(git rev-parse --show-toplevel)

    # Create the worktrees directory if it doesn't exist
    mkdir -p "$REPO_ROOT/worktrees"

    # Get a list of all remote branches excluding the current branch
    branches=$(git branch -r | sed 's/origin\///g' | sed '/HEAD/d' | tr -d ' ')

    # Get the name of the current branch
    current_branch=$(git rev-parse --abbrev-ref HEAD)

    # Iterate over each branch
    for branch in $branches; do
        # Skip the loop iteration if this is the current branch
        if [[ "$branch" == "$current_branch" ]]; then
            continue
        fi
        
        # Replace slashes with underscores in branch name for directory naming
        safe_branch_name=$(echo "$branch" | tr '/' '_')

        # Construct the path to where the worktree for this branch would be
        worktree_path="$REPO_ROOT/worktrees/$safe_branch_name"

        # Check if a worktree already exists for this branch
        if [[ ! -d "$worktree_path" ]]; then
            # No worktree exists, so create a new one for this branch
            git worktree add "$worktree_path" "$branch"
        else
            # A worktree already exists for this branch
            echo "Worktree already exists for branch $branch at $worktree_path"
        fi
    done
}

# abgrep: grep all branches
abgrep(){
    REGEX=$1
    branches=$(git branch -r | sed 's/origin\///g' | sed '/HEAD/d' | tr -d ' ')

    curr_branch=$(git branch | grep "*" | sed 's/* //g')
    for branch in $branches; do
        git checkout $branch
        echo "Checking $branch"
        grep -r $REGEX
        echo '\n\n\n\n\n'
    done
    git checkout $curr_branch
}

# wgrep: grep worktrees
wgrep(){
    python $BASHER/src/py_scripts/wgrep.py $@
}

# wch: change to worktree
wch(){
    cd $(git rev-parse --show-toplevel)/worktrees/$1
}

# pipp: print python package path
pipp(){
    PKG=${1:-"site"}
    GO=${2:-0}
    CURR=$(python -c "import $PKG; import os; print(os.path.dirname($PKG.__file__))" 2> /dev/null)

    if [ "$GO" -eq 1 ]; then
        cd $CURR
    else
        echo $CURR
    fi
}

# pips: print python site-packages path
pips(){
    LCL_PATH="$(pipp site 0)/site-packages"
    if [ -z $1 ]; then
        cd $LCL_PATH
    else
        echo $LCL_PATH
    fi
}

# efunc: edit bash functions
efunc(){
    code $HOME/.bash_functions
}

# ealias: edit bash aliases
ealias(){
    code $HOME/.bash_aliases
}

# evars: edit bash environment variables
evars(){
    code $HOME/.bash_env_vars
}

# eenv: edit bash environment
eenv(){
    code $HOME/.bash_env
}

# gr: git reset
gr(){
    git reset $@
}

# rcb: reset current branch
rcb(){
    git reset $1 origin/$(git rev-parse --abbrev-ref HEAD)
}

# cdi: change directory to isl
cdi(){
    cd $ISL/$1
}

# cdd: change directory to deepwave_debug
cdd(){
    cd $DEEPWAVE_DEBUG/$1
}

# cdb: change directory to basher
cdb(){
    cd $BASHER/$1
}

#cdc: change directory to conda prefix
cdc(){
    cd $CONDA_PREFIX/$1
}

# cdr: change directory to repo
cdr(){
    cd $REPO/$1
}

# eplat: edit platform
eplat(){
    code $BASHER/src/platform/$1
}

# mhr: masthay helpers reinstall -- deprecated -- use pip install -e .
mhr(){
    PREV=$(pwd)
    cdr masthay_helpers
    source reinstall.sh
    cd $PREV
}

# check_devices: check devices
check_devices(){
    python -c "from misfit_toys.utils import check_devices; check_devices('$1')"
}

# cst: "check status" -- repeatedly print contents of file with sleeps
cst(){
    sleep_time=${1:-3}
    iterations=${2:-1000}
    FILE=${3:-"/tmp/debug.out"}
    c1=${4:-magenta}
    c2=${5:-green}
    for ((i=0; i<iterations; i++)); do
        if ((i % 2 == 0)); then
            cecho --color=$c1 "$(cat $FILE)"
        else
            cecho --color=$c2 "$(cat $FILE)"
        fi
        sleep $sleep_time
    done
}

# phelp: "python help"
phelp() {
    python $BASHER/src/py_scripts/phelp.py $@
}

# gce: "git commit empty"
gce(){
    git commit --allow-empty $@
}

# rcache: remove __pycache__ recursively
rcache(){
    find . -type d -name "__pycache__" -print -exec rm -rf {} \; 2> /dev/null
}

# pcr: "pre-commit run"
pcr(){
    pre-commit clean
    pre-commit install
}

# gds: "git difftool staged"
gds(){
    git difftool --staged @{u}
}

# git-hook-em: set git hooks path -- deprecated
git-hook-em(){
    git config --global core.hooksPath $HOOK_EM/.git/hooks
}

# update_pre_commit: update pre-commit hooks
update_pre_commit() {
    # Check if HOOK_EM environment variable is set
    if [[ -z "${HOOK_EM}" ]]; then
        echo "Error: The HOOK_EM environment variable is not set."
        return 1
    fi

    # Check if REPO environment variable is set
    if [[ -z "${REPO}" ]]; then
        echo "Error: The REPO environment variable is not set."
        return 1
    fi

    # Find all directories in your $REPO variable, excluding any paths that contain $HOOK_EM
    find "${REPO}" -maxdepth 1 -mindepth 1 -type d | grep -v "${HOOK_EM}" | while read -r repo_dir; do
        echo "Updating repository: ${repo_dir}"
        
        # clean pre-existing directories
        rm -rf "${repo_dir}/.gitlint_rules"

        # Copy the pre-commit config files into the repository
        cp "${HOOK_EM}/.pre-commit-config.yaml" "${repo_dir}/"
        cp "${HOOK_EM}/.gitattributes" "${repo_dir}/"
        cp "${HOOK_EM}/.gitlint" "${repo_dir}/"
        cp -r "${HOOK_EM}/.gitlint_rules" "${repo_dir}/.gitlint_rules"

        # Change directory to the repository
        pushd "${repo_dir}" > /dev/null || return

        # Remove commit-msg
        rm .git/hooks/commit-msg 2> /dev/null 2>&1
        gitlint install-hook

        # Clean the pre-commit environment
        pre-commit clean > /dev/null 2>&1
        
        # Install the pre-commit hook
        pre-commit install > /dev/null 2>&1

        # Return to the original directory
        popd > /dev/null || return
    done
}

# lsh: "list hidden" -- list ONLY hidden files
lsh(){
    ls -ld .?* | awk '{print $9}' | grep -v '[.][.]'
}

# gca: "git commit amend"
gca(){
    git commit --amend
}

# grt: "git root"
grt(){
    git rev-parse --show-toplevel
}

# sfi: "sort file in place"
sfi() {
    # Check if the file path is provided
    if [ -z "$1" ]; then
        echo "No file path provided."
        return 1
    fi

    local file_path="$1"

    # Check if the file exists
    if [ ! -f "$file_path" ]; then
        echo "File does not exist: $file_path"
        return 1
    fi

    # Sort the file and overwrite it
    sort "$file_path" > "$file_path.sorted"
    mv "$file_path.sorted" "$file_path"
}

# cimp: "check imports" -- create list of all imports and check against requirements.txt
cimp() {
    local temp_file="/tmp/requirements_temp.txt"
    local requirements_file="$(grt)/requirements.txt"
    RES=$(find $(grt) -name "*.py" -exec grep -E "^(import|from)" {} \; | awk '{print $2}' | sed 's/\([^\.]*\)\..*/\1/' | sort | uniq)
    PIP_LIST=$(pip list)

    > "$temp_file" # Empty the file before starting

    for res in $RES; do
        MATCH=$(echo "$PIP_LIST" | grep -w "$res" | awk '{printf "%s>=%s\n", $1, $2}')
        if [[ ! -z "$MATCH" ]]; then
            echo "$MATCH" >> "$temp_file"
        fi
    done

    sfi "$temp_file"
    sfi "$requirements_file"

    git difftool -y "$temp_file" "$requirements_file"
}

# stats: compute stats on a file (csv file?)
stats(){
    python $BASHER/src/py_scripts/stats.py $@
}

# ccsv: "color csv" 
ccsv(){
    python $BASHER/src/py_scripts/ccsv.py $@
}

# trich: toggle RICH_LOG
trich(){
    if [ -z $RICH_LOG ]; then
        export RICH_LOG='/tmp/rich.ans'
    else
        unset RICH_LOG
    fi
    echo "RICH_LOG=$RICH_LOG"
}

# sansi: strip all ansi codes
sansi(){
    sed $@ 's/\x1b\[[0-9;]*[mGKFH]//g'
}

# ransi: replace all ansi codes with a marker
ransi(){
    local replace=${1:-"ANSI_MARKER"}
    sed "s/\x1b\[[0-9;]*[mGKFH]/$replace/g"
}

# salpha: strip non-alpha numeric symbols
salpha(){
    sed "$@" 's/[^0-9a-zA-Z .+-]//g'
}

# pip_ver: pip version
pip_ver(){
    pip show $1 2> /dev/null | grep "Version"
}

# my_black: black 80 chars, no string norm, preview, skip magic trailing comma
my_black(){
    black --line-length 80 --skip-string-normalization --preview --skip-magic-trailing-comma $@
}

# esite: edit site customize file
esite(){
    local prev=$(pwd)
    pips
    code sitecustomize.py
    cd $prev
}

# gsrt: "git super root" -- go to the root of the repo, disregarding submodules
gsrt(){
    local super=$(git rev-parse --show-superproject-working-tree)
    if [ -z $super ]; then
        echo "$(git rev-parse --show-toplevel)"
    else
        echo "$super"
    fi
}

# gsmu: git submodule update --recursive --remote
gsmu(){
    git submodule update --recursive --remote
}

# gsync: sync GitHookEm settings
gsync(){
    local prev=$(pwd)
    cd $(gsrt)
    cd GitHookEm
    ./sync.sh
    cd $prev
}

# cdh: cd $HOME/$1
cdh(){
    cd $HOME/$1
}

# ufw_monitor: run ufw_monitor.py
ufw_monitor(){
    sudo $(which python3) $BASHER/src/py_scripts/ufw_monitor.py --basher $BASHER $@
}

# glcf: "git log full"
glcf(){
    git log --graph --decorate --all --format="%C(auto)%h (%ar) %s%d%n%b"
}

# tst: Run pytest in tests directory
tst(){
    local show_code=${1:-0}
    local prev=$(pwd)
    cdi
    mytest tests $show_code
    cd $prev
}

# gslf: "git show log full"
gslf(){
    local file=$1
    git log --color --pretty=format:"%h - %s" -p -- $file > /tmp/git_log_full.ans
    code /tmp/git_log_full.ans
}

# mytest: monitor pytest, plus pun intended
mytest() {
    local file=${1:-"tests"}
    local show_code=${2:-0}
    pytest $file --color=yes > /tmp/pytest.ans &
    pytest_pid=$!
    if [[ $show_code -eq 1 ]]; then
        code /tmp/pytest.ans
    fi

    # Initialize the counter
    dead_count=0

    while true; do
        sleep 2 
        
        # Find the line numbers for "Captured stderr call" and "short test summary info"
        err_line=$(grep -n "Captured stderr call" /tmp/pytest.ans | head -n 1 | cut -d: -f1)
        sum_line=$(grep -n "short test summary info" /tmp/pytest.ans | head -n 1 | cut -d: -f1)

        # Check if both markers are found
        if [[ -n "$err_line" && -n "$sum_line" && $sum_line -gt $err_line ]]; then
            # Delete lines from err_line to sum_line, excluding sum_line
            sed -i "${err_line},$(($sum_line - 1))d" /tmp/pytest.ans
            break
        fi

        # Check if pytest is still running
        if ! kill -0 $pytest_pid 2> /dev/null; then
            ((dead_count++))
            if [[ $dead_count -ge 3 ]]; then
                # echo "pytest process has finished. Exiting..."
                clear
                cat /tmp/pytest.ans
                break
            fi
        else
            # Reset dead count if pytest is still running
            dead_count=0
        fi
        clear
        cat /tmp/pytest.ans
    done
}

# sclr: "string color" -- ctxt -l "$1" -c $1
sclr(){
    ctxt -l "$1" -c $1
}

# cmts: "count comments" -- count the number of comments in a file
cmts(){
    local file=$1;
    local num_cmts=${2:-5}
    if [[ $(cat $file | sed 's/.*#.*/#/' | sed 's/^\([#]*\).*/\1/' | tr '\n' '@' | sed 's/#@/#/g' | tr '@' ' ' | grep $(perl -E "say '#' x $num_cmts") | wc -l) -eq 1 ]]; then
        echo "$file"
    fi
}

# cmta: "count comments all" -- count the number of comments in all files
cmta(){
    local dir=${1:-.}
    local num_cmts=${2:-5}
    find $dir -type f -name "*.py" | while read file; do
        cmts $file $num_cmts
    done
}
echo "ignore this" > /dev/null

source ~/.platform/functions




