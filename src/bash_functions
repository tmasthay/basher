~/.secrets/build_souper_secrets.sh
source ~/.secrets/functions

# scl: "get_color" -- Set terminal color
scl() {
    local color_value=$1

    # Map user-friendly color names to RGB values
    case "$color_value" in
    orange) color_value='rgb530' ;;
    maroon) color_value='rgb320' ;;
    olive) color_value='rgb330' ;;
    navy) color_value='rgb003' ;;
    teal) color_value='rgb033' ;;
    lime) color_value='rgb250' ;;
    coral) color_value='rgb550' ;;
    salmon) color_value='rgb540' ;;
    beige) color_value='rgb542' ;;
    mint) color_value='rgb253' ;;
    lavender) color_value='rgb432' ;;
    plum) color_value='rgb302' ;;
    indigo) color_value='rgb104' ;;
    gold) color_value='rgb530' ;;
    pink) color_value='rgb532' ;;
    tan) color_value='rgb531' ;;
    coffee) color_value='rgb321' ;;
    chocolate) color_value='rgb320' ;;
    azure) color_value='rgb156' ;;
    silver) color_value='rgb555' ;;
    rand)
        # Generate random RGB values between 0-5
        local r=$((RANDOM % 6))
        local g=$((RANDOM % 6))
        local b=$((RANDOM % 6))
        color_value="rgb$r$g$b"
        ;;
    esac

    case "$color_value" in
    black) tput setaf 0 ;;
    red) tput setaf 1 ;;
    green) tput setaf 2 ;;
    yellow) tput setaf 3 ;;
    blue) tput setaf 4 ;;
    magenta) tput setaf 5 ;;
    cyan) tput setaf 6 ;;
    white) tput setaf 7 ;;
    rgb[0-5][0-5][0-5])
        local r="${color_value:3:1}"
        local g="${color_value:4:1}"
        local b="${color_value:5:1}"
        local code=$((16 + (36 * r) + (6 * g) + b))
        tput setaf $code
        ;;
    gray[0-9] | gray1[0-9] | gray2[0-3])
        local gray_value="${color_value:4}"
        local code=$((232 + gray_value))
        tput setaf $code
        ;;
    *)
        echo "Unknown color: $color_value" >&2
        return 1
        ;;
    esac
}

# ctxt: color text
ctxt() {
    python $BASHER/src/py_scripts/ctxt.py $@
}

# ftxt: file text colored
ftxt() {
    FILE=$1
    OPTS=$2
    READ_FROM_FILE=${3:-""}

    # Check if -f (file read) flag is present, then prepend it to the file argument
    if [ "$READ_FROM_FILE" = "-f" ]; then
        FILE_ARG="-f $FILE"
    else
        FILE_ARG="$FILE"
    fi

    # Now call ctxt with the file argument and the contents of the options file
    ctxt $FILE_ARG $(cat "$OPTS")
}

# cecho_legacy: colored echo legacy before scl function
cecho_legacy() {
    local no_newline=0
    local color_value

    # Check for -n option
    if [ "$1" = "-n" ]; then
        no_newline=1
        shift
    fi

    # Check for --color= option
    if [[ "$1" =~ ^--color= ]]; then
        color_value="${1#*=}" # Extract the value after the '=' sign
        shift
    else
        color_value="red"
    fi

    local text="$@"

    case "$color_value" in
    black) tput setaf 0 ;;
    red) tput setaf 1 ;;
    green) tput setaf 2 ;;
    yellow) tput setaf 3 ;;
    blue) tput setaf 4 ;;
    magenta) tput setaf 5 ;;
    cyan) tput setaf 6 ;;
    white) tput setaf 7 ;;
    rgb[0-5]_[0-5]_[0-5])
        local r="${color_value:3:1}"
        local g="${color_value:5:1}"
        local b="${color_value:7:1}"
        local code=$((16 + (36 * r) + (6 * g) + b))
        tput setaf $code
        ;;
    gray[0-9] | gray1[0-9] | gray2[0-3])
        local gray_value="${color_value:4}"
        local code=$((232 + gray_value))
        tput setaf $code
        ;;
    *)
        echo "Unknown color: $color_value" >&2
        return 1
        ;;
    esac

    if [ $no_newline -eq 1 ]; then
        echo -n "$text"
    else
        echo "$text"
    fi

    tput sgr0 # Reset text attributes to normal without clearing screen.
}

# see_fonts: see fonts
see_fonts() {
    fc-list | cut -f2 -d':' | sort -u
}

# set_var: set environment variable
set_var() {
    if [ "$#" -ne 1 ]; then
        echo "Usage: echo VAR_VALUE | set_var VAR_NAME"
        return 1
    fi

    read -r VAR_CONTENT
    eval "export $1=\"$VAR_CONTENT\""
}

# prepend_env_var: conda environment helpers
prepend_env_var() {
    # Check if the environment variable is already set
    if [ -z "${!1}" ]; then
        # If not, set the environment variable to the new value without a trailing colon
        export $1=$2
    else
        # If yes, store the old value and prepend the new value with a colon separator
        export OLD_$1=${!1}
        export $1=$2:${!1}
    fi
}

# revert_env_var: conda environment helpers
revert_env_var() {
    local old_var="OLD_$1"
    eval "export $1=\"\${$old_var}\""

    # Unset the old value
    unset OLD_$1
}

# start_ssh: start ssh agent
start_ssh() {
    eval "$(ssh-agent -s)"
}

# ssh_add_all: add all ssh keys
ssh_add_all() {
    ssh-add $(find ~/.ssh -type f -name 'id_*' ! -name '*.pub')
}

# matlab: start matlab
matlab() {
    LAST_DIR=$(pwd)
    cd ~/MATLAB/Source
    ~/MATLAB/R2023a/bin/matlab &
    cd $LAST_DIR
}

# pfs: print file contents recursively
pfs() {
    local dir=$1
    local pattern=$2
    local regex=$3 # get the function's third argument
    find "$dir" -type f -name "$pattern" -print0 | while IFS= read -r -d $'\0' file; do
        echo "$file"
        echo "$(printf '%.0s*' {1..80})"
        # If regex is provided, use it to filter file contents
        if [[ -n "$regex" ]]; then
            grep -E "$regex" "$file" || echo "No match found for regex '$regex'"
        else
            cat "$file"
        fi
        echo "$(printf '%.0s*' {1..80})"
    done
}

# grb: git rebase
grb() {
    find . -name '*.orig' -delete
    find . -name '*LOCAL*' -delete
    find . -name '*REMOTE*' -delete
    find . -name '*BACKUP*' -delete
    find . -name '*.~HEAD~' -delete
    find . -name '*BASE*' -delete
}

# kkp: kill process by port
kkp() {
    TMP=$(lsof -i :$1 | awk '{print $2}' | sed -n '2p')
    echo "kill $TMP"
    kill $TMP
}

# vit: vim with terminal
vit() {
    vim -c "vertical terminal" $1
}

# rclr: random color
rclr() {
    red_channel=$((RANDOM % 6))
    green_channel=$((RANDOM % 6))
    blue_channel=$((RANDOM % 6))
    color_value="rgb$red_channel$green_channel$blue_channel"
    echo $color_value
}

# gpu_mem: see gpu memory
gpu_mem() {
    my_color=${1:-$(rclr)}
    timestamp=${2:-0}

    ctxt "$timestamp sec    " -l -c $my_color -e
    echo -n "    "
    nvidia-smi --query-gpu=index,memory.used --format=csv,nounits,noheader | while IFS=", " read -r index memory; do
        memory_gb=$(awk "BEGIN {printf \"%.2f\",${memory}/1024}")
        ctxt -l "    GPU #${index}: ${memory_gb} GB" -c $my_color -e
        echo -n "    "
    done
    echo
}

# mgpu: monitor gpu
mgpu() {
    iterations=${3:-1000}
    sleep_time=${4:-3}
    c1=${1:-$(rclr)}
    c2=${2:-$(rclr)}
    ctxt "Color 1: $c1" -l -c $c1 -e
    echo -n "    "
    ctxt "Color 2: $c2" -l -c $c2
    for ((i = 0; i < iterations; i++)); do
        if ((i % 2 == 0)); then
            gpu_mem "$c1" $((i * sleep_time))
        else
            gpu_mem "$c2" $((i * sleep_time))
        fi
        sleep $sleep_time
    done
}

# jail_list: list all banned IPs
jail_list() {
    JAIL=${1:-"sshd"}
    JAIL_LIST=$(sudo fail2ban-client status $JAIL | grep "Banned")
    JAIL_LIST=$(echo $JAIL_LIST | awk '{for (i=5; i<=NF; i++) printf $i " "; print ""}')
    echo $JAIL_LIST | tr ' ' '\n'
}

# ban_ip: ban an IP
ban_ip() {
    IP=$1
    JAIL=${2:-"sshd"}
    sudo fail2ban-client set $JAIL banip $IP
}

# unban_ip: unban an IP
unban_ip() {
    IP=$1
    JAIL=${2:-"sshd"}
    sudo fail2ban-client set $JAIL unbanip $IP
}

# unban_ip_regex: unban all IPs matching a regex
unban_ip_regex() {
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}
    local JAIL=${2:-"sshd"}
    local JAIL_LIST=$(jail_list $JAIL)
    JAIL_LIST=$(echo $JAIL_LIST | tr ' ' '\n' | grep $REGEX)
    for IP in $JAIL_LIST; do
        echo "Unbanning $IP"
        unban_ip $IP $JAIL 2>/dev/null >/dev/null
    done
}

# unban_first: unban the first IP
unban_first() {
    JAIL=${1:-"sshd"}
    unban_ip $(sudo fail2ban-client status $JAIL | grep "Banned" | awk '{print $5}')
}

# cdmr: change directory to most recent
cdmr() {
    DIR=${1:-$CDMR_DEFAULT}
    cd $DIR/$(ls $DIR -tr | tail -n 1)
}

# ensure_ssh_agent: ensure ssh agent is running
ensure_ssh_agent() {
    # Find all agent sockets based on the file structure
    AGENT_SOCKETS=$(find /tmp/ssh-* -type d -exec find {} -name "agent.*" \;)

    # Convert AGENT_SOCKETS into an array
    SOCKET_ARRAY=($AGENT_SOCKETS)

    # If there's no active agent socket
    if [[ ${#SOCKET_ARRAY[@]} -eq 0 ]]; then
        echo "No active SSH agent socket found. Starting one now..."
        eval $(ssh-agent -s)
        echo "SSH agent started with PID $SSH_AGENT_PID"

        # If there's exactly one agent socket
    elif [[ ${#SOCKET_ARRAY[@]} -eq 1 ]]; then
        export SSH_AUTH_SOCK=${SOCKET_ARRAY[0]}
        echo "Bound to existing SSH agent at $SSH_AUTH_SOCK"

        # If there's more than one agent socket
    else
        echo "Warning: Multiple SSH agent sockets found (${#SOCKET_ARRAY[@]} sockets)."
        echo "To kill all active ssh-agents and start afresh, run:"
        echo "pkill -u $USER ssh-agent && ensure_ssh_agent"
    fi
    ssh_add_all
}

# bpushm: basher push main
bpushm() {
    PREV=$(pwd)
    cd $BASHER
    gau
    gcm $1
    gp
    cd $PREV
}

# bpush: basher push
bpush() {
    PREV=$(pwd)
    cde $BASHER
    echo $(pwd)
    gau
    gc
    gp
    cd $PREV
}

# bpull: basher pull
bpull() {
    PREV=$(pwd)
    cd $BASHER
    git pull
    cd $PREV
}

# dwre: deepwave reinstall and test
dwre() {
    RETEST=${1:-0}
    REDOWNLOAD_DATA=${2:-0}
    CURR_PATH=$(pwd)
    cdi
    ./reinstall_and_test.sh $RETEST $REDOWNLOAD_DATA
    cd $CURR_PATH
}

# tyc: remove files from path matching regex
tyc() {
    CURR_PATH=${2:-.}
    REGEX=${1:-"AnExpressionThatWillNeverMatchAnythingHOORAH.NOPE"}

    if [[ "$REGEX" == ".*" || "$REGEX" == "*" ]]; then
        echo "Cannot clean everything"
        return
    fi

    RESULTS=$(find . -type f -name "$REGEX")
    echo $RESULTS
    find . -type f -name "$REGEX" -delete
}

# sfunc: source bash functions
sfunc() {
    source ~/.bash_functions
}

# salias: source bash aliases
salias() {
    source ~/.bash_aliases
}

# svars: source bash environment variables
svars() {
    source ~/.bash_env_vars
}

# senv: source bash environment
senv() {
    source ~/.bash_env
}

# shelp: source bash helpers
shelp() {
    source ~/.bash_source_helpers
}

# codeo: open files in vscode
codeo() {
    PATTERN=${1:-"*.jpg"}
    CURR_PATH=${2:-.}
    LIMIT=${3:-3}
    RES=$(find . -type f -name "$PATTERN")
    NUM_RES=$(echo $RES | wc -l)
    if [[ $NUM_RES -eq 0 ]]; then
        echo "No results found"
        return
    fi
    if [[ $NUM_RES -gt $LIMIT ]]; then
        echo "$NUM_RES results found. Opening only first $LIMIT"
        RES=$(echo $RES | head -n $LIMIT)
        return
    fi
    echo "Opening following files"
    echo $RES
    code $RES
}

# gsg: see unstaged git files
gsg() {
    KEEP=${1:-modified}
    OMIT=${2:-.gitkeep}
    git status -uno | grep -E "$KEEP" | grep -vE "$OMIT" | awk '{print $2}'
}

# gag: add git files matching gsg convention
gag() {
    ga $(gsg $1 $2)
}

# ge: "git everything" - gau; gc; gp
ge() {
    gau
    gc
    gp
}

# gem: "git everything message" - gau; gcm $1; gp
gem() {
    gau
    gcm $1
    gp
}

# geg: "git everything gsg" - gau; gag $1 $2; gc; gp
geg() {
    gag $1 $2
    gc
    gp
}

# ufw_bak: backup ufw rules
ufw_bak() {
    mkdir -p ~/.backups/ufw
    if [ -f /etc/ufw/user.rules ]; then
        sudo cp /etc/ufw/user.rules ~/.backups/ufw/user.rules
        if [ $? -eq 0 ]; then
            echo "Backup successful."
        else
            echo "Backup failed."
        fi
    else
        echo "/etc/ufw/user.rules does not exist."
    fi
}

# ufw_bak2: backup ufw rules
ufw_bak2() {
    if [ -f ~/.backups/ufw/user.rules ]; then
        sudo cp ~/.backups/ufw/user.rules ~/.backups/ufw/user.rules.bak
        if [ $? -eq 0 ]; then
            echo "Double backup successful."
        else
            echo "Double backup failed."
        fi
    else
        echo "~/.backups/ufw/user.rules does not exist."
    fi
}

# ufw_restore: restore ufw rules
ufw_restore() {
    ufw_bak2
    if [ -f ~/.backups/ufw/user.rules ]; then
        sudo cp ~/.backups/ufw/user.rules /etc/ufw/user.rules
        if [ $? -eq 0 ]; then
            sudo ufw reload
            echo "Restore and reload successful."
        else
            echo "Restore failed."
        fi
    else
        echo "~/.backups/ufw/user.rules does not exist."
    fi
}

# ufw_swap_bak: swap ufw rules with backup
ufw_swap_bak() {
    # Create a temporary backup of the current 'user.rules'
    sudo cp ~/.backups/ufw/user.rules ~/.backups/tmp.rules || {
        echo "Failed to create temp backup"
        return 1
    }

    # Swap 'user.rules' and 'user.rules.bak'
    sudo mv ~/.backups/ufw/user.rules.bak ~/.backups/ufw/user.rules || {
        echo "Failed to swap backups"
        return 1
    }

    # Replace the backup with the temporary file
    sudo mv ~/.backups/tmp.rules ~/.backups/ufw/user.rules.bak || {
        echo "Failed to finalize swap"
        return 1
    }
}

# ufw_fsd_legacy: find and delete ufw rules containing SCALPEL_DENY
ufw_fsd_legacy() {
    # Find the first rule with "SCALPEL_DENY", get its number and IP
    local rule_info=$(sudo ufw status numbered | grep "SCALPEL_DENY" | awk 'NR==1{print $2, $(NF-2)}' | tr -d '[]')
    local rule_num=$(echo $rule_info | awk '{print $1}')
    local from_ip=$(echo $rule_info | awk '{print $2}')

    # Check if a rule was found
    if [[ -z "$rule_num" ]]; then
        echo "ufw_fsd found no SCALPEL_DENY directives."
        return 1
    else
        # Delete the rule; use --force to bypass confirmation
        sudo ufw --force delete $rule_num
        echo "Deleted rule number $rule_num for IP $from_ip containing SCALPEL_DENY."
    fi
}

# ufw_fsd: find and delete ufw rules containing SCALPEL_DENY
ufw_fsd() {
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}
    local rule_info=$(sudo ufw status numbered | grep "SCALPEL_DENY")
    rule_info=$(echo "$rule_info" | grep "$REGEX")
    rule_info=$(echo "$rule_info" | sed 's/\[[ ]*\([0-9][0-9]*\)\]/\1/g')
    rule_info=$(echo "$rule_info" | awk '{print $1,$5}')
    local rule_num=$(echo $rule_info | awk '{print $1}')
    local from_ip=$(echo $rule_info | awk '{print $2}')

    # Check if a rule was found
    if [[ -z "$rule_num" ]]; then
        echo "ufw_fsd found no SCALPEL_DENY directives matching REGEX='$REGEX'."
        return 1
    else
        # Delete the rule; use --force to bypass confirmation
        sudo ufw --force delete $rule_num
        echo "Deleted rule number $rule_num for IP $from_ip containing SCALPEL_DENY."
        return $from_ip
    fi
}

# ufw_all_scalpel: find and delete all ufw rules containing SCALPEL_DENY
ufw_all_scalpel() {
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}
    # Run the backup function at the beginning
    ufw_bak2
    ufw_bak

    # Loop until ufw_fsd returns 1
    while true; do
        ufw_fsd $REGEX
        if [[ $? -eq 1 ]]; then
            echo "All SCALPEL_DENY directives purged. To restore previous config, run ufw_restore."
            return 0
        fi
    done
}

# ufw_all_scalpel_unban: find and delete all ufw rules containing SCALPEL_DENY
ufw_all_scalpel_unban() {
    local REGEX=${1:-"[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*"}

    ufw_all_scalpel $REGEX
    unban_ip_regex $REGEX
}

# unr_alias: unravel an alias
unr_alias() {
    alias $1 2>/dev/null | sed -E "s/alias $1='(.*)'/\1/;s/\$[0-9]\{1,\}//g" | envsubst
}

# atrm_all: remove all at jobs
atrm_all() {
    num_calls=$(atq | wc -l)

    for ((i = 1; i <= num_calls; i++)); do
        atrm $(atq | awk '{print $1}' | head -n 1)
    done
}

# jbr: "jupyter bind remote"
jbr() {
    REMOTE_DOMAIN=$1
    HOST_PORT=${2:-8889}
    REMOTE_PORT=${3:-8888}
    ssh -N -f -L localhost:$HOST_PORT:localhost:$REMOTE_PORT $REMOTE_DOMAIN
}

# jmr: "jupyter make remote"
jmr() {
    PORT=${1:-8888}
    MODE=${2:-"lab"}
    jupyter $MODE --no-browser --port=$PORT
}

# gcp: "git clean preview"
gcp() {
    git clean -ndfx
}

# exp: "expand environment variables"
exp() {
    eval echo $1
}

# cde: "cd expand"
cde() {
    cd "$(exp $1)"
}

# ups: "update setup"
ups() {
    local TMP_BASHER=$(exp $BASHER)
    python $TMP_BASHER/src/py_scripts/ups.py
}

# gmu: "git merge up"
gmu() {
    TARGET=${1:-"main"}
    CURR=$(git rev-parse --abbrev-ref HEAD)
    git pull
    git checkout $TARGET
    git pull
    git merge $CURR
    git push
    git checkout $CURR
}

# gmd: "git merge down"
gmd() {
    SRC=${1:-"main"}
    CURR=$(git rev-parse --abbrev-ref HEAD)
    git pull
    git checkout $SRC
    git pull
    git checkout $CURR
    git merge $SRC
}

# no_suspend: prevent suspend
no_suspend() {
    gnome-session-inhibit --inhibit-only --inhibit "idle:suspend" &
}

# cver: "check version"
cver() {
    cat setup.py | grep "version"
}

# cemu: "CI git-everything merge up"
cemu() {
    ups
    gem $1
    gmu
}

# rpython "rich python" -- deprecated
rpython() {
    python $BASHER/src/py_scripts/rich_python.py $@
}

# cols: columnize output
cols() {
    python $BASHER/src/py_scripts/cols.py $@
}

# user_funcs_cols: see user functions
user_funcs_cols() {
    COLS=${1:-5}
    BASH_FUNCS=$(cat "$HOME/.bash_functions")
    PLATFORM_FUNCS=$(cat "$HOME/.platform/functions")
    grep_regex='.*()[ ]*{'
    sed_regex='s/\(.*\)[ ]*([ ]*)[ ]*\{/\1/'
    FIRST=$(echo "$BASH_FUNCS" | grep -E $grep_regex | sed -E "$sed_regex" | grep -v "^ " | grep -v "^#")
    SECOND=$(echo "$PLATFORM_FUNCS" | grep -E $grep_regex | sed -E "$sed_regex" | grep -v "^ " | grep -v "^#")
    TOTAL=$(echo "$FIRST\n$SECOND" | sort | uniq)
    cols -c $COLS "$(echo $TOTAL)"
}

# user_funcs: see user functions
user_funcs() {
    cat "$HOME/.bash_functions" "$HOME/.platform/functions" | grep "^# " | sed 's/# //' | sort
}

# undoc_funcs: see undocumented functions
undoc_funcs() {
    user_funcs | awk '{print $1}' | sed 's/://' >/tmp/user_funcs.txt
    user_funcs_cols 1 >/tmp/user_funcs_cols.txt
    code --diff /tmp/user_funcs.txt /tmp/user_funcs_cols.txt
}

# ufd: "user functions docs"
ufd() {
    grep_regex='^# \(.*\): \(.*\)'
    sed_regex='s/^# \(.*\)/\1/'
    awk_cmd='{printf "%-30s %s\n", $1, $2}'
    echo 'USER FUNCTIONS'
    grep $grep_regex "$HOME/.bash_functions" | sort | uniq | sed $sed_regex | awk -F':' "$awk_cmd"
    echo
    echo
    echo
    echo 'PLATFORM FUNCTIONS'
    grep $grep_regex "$HOME/.platform/functions" | sort | uniq | sed $sed_regex | awk -F':' "$awk_cmd"
}

# all_git: run a git command in all git repos
all_git() {
    CMD=$1
    ROOT=${2:-$REPO}
    directories=$(find "$ROOT" -type d -name ".git" -exec dirname {} \;)

    # Iterate over each directory
    for dir in $directories; do
        cd "$dir" || continue # Change to the directory, or skip to the next iteration if cd fails
        eval "$CMD"           # Pull the latest changes
    done
}

# agfetch: fetch all git repos
agfetch() {
    all_git '
        git fetch origin;
        res=$(git log HEAD..origin/HEAD --oneline);
        if [[ -z "$res" ]]; then
            echo "$dir -- ALREADY UP TO DATE";
        else
            echo "$dir -- MERGEABLE: Run git merge origin to update";
        fi
    ' "$1"
}

# agpull: pull all git repos
agpull() {
    all_git 'git pull' $1
}

# agsee: see all git repos
agsee() {
    all_git 'echo "$dir"' $1
}

# agmo: merge all git repos
agmo() {
    all_git 'git merge origin' $1
}

# create_worktrees: create worktrees for all remote branches
create_worktrees() {
    # Get the absolute path to the root of the repo
    REPO_ROOT=$(git rev-parse --show-toplevel)

    # Create the worktrees directory if it doesn't exist
    mkdir -p "$REPO_ROOT/worktrees"

    # Get a list of all remote branches excluding the current branch
    branches=$(git branch -r | sed 's/origin\///g' | sed '/HEAD/d' | tr -d ' ')

    # Get the name of the current branch
    current_branch=$(git rev-parse --abbrev-ref HEAD)

    # Iterate over each branch
    for branch in $branches; do
        # Skip the loop iteration if this is the current branch
        if [[ "$branch" == "$current_branch" ]]; then
            continue
        fi

        # Replace slashes with underscores in branch name for directory naming
        safe_branch_name=$(echo "$branch" | tr '/' '_')

        # Construct the path to where the worktree for this branch would be
        worktree_path="$REPO_ROOT/worktrees/$safe_branch_name"

        # Check if a worktree already exists for this branch
        if [[ ! -d "$worktree_path" ]]; then
            # No worktree exists, so create a new one for this branch
            git worktree add "$worktree_path" "$branch"
        else
            # A worktree already exists for this branch
            echo "Worktree already exists for branch $branch at $worktree_path"
        fi
    done
}

# abgrep: grep all branches
abgrep() {
    REGEX=$1
    branches=$(git branch -r | sed 's/origin\///g' | sed '/HEAD/d' | tr -d ' ')

    curr_branch=$(git branch | grep "*" | sed 's/* //g')
    for branch in $branches; do
        git checkout $branch
        echo "Checking $branch"
        grep -r $REGEX
        echo '\n\n\n\n\n'
    done
    git checkout $curr_branch
}

# wgrep: grep worktrees
wgrep() {
    python $BASHER/src/py_scripts/wgrep.py $@
}

# wch: change to worktree
wch() {
    cd $(git rev-parse --show-toplevel)/worktrees/$1
}

# pipp: print python package path
pipp() {
    PKG=${1:-"site"}
    GO=${2:-0}
    CURR=$(python -c "import $PKG; import os; print(os.path.dirname($PKG.__file__))" 2>/dev/null)

    if [ "$GO" -eq 1 ]; then
        cd $CURR
    else
        echo $CURR
    fi
}

# pips: print python site-packages path
pips() {
    LCL_PATH="$(pipp site 0)/site-packages"
    if [ -z $1 ]; then
        cd $LCL_PATH
    else
        echo $LCL_PATH
    fi
}

# edit_file: edit file
efile() {
    local cmd=$(echo $GIT_EDITOR | awk '{print $1}')
    $cmd $1
}

# efunc: edit bash functions
efunc() {
    efile $HOME/.bash_functions
}

# ealias: edit bash aliases
ealias() {
    efile $HOME/.bash_aliases
}

# evars: edit bash environment variables
evars() {
    efile $HOME/.bash_env_vars
}

# eenv: edit bash environment
eenv() {
    efile $HOME/.bash_env
}

# gr: git reset
gr() {
    git reset $@
}

# rcb: reset current branch
rcb() {
    git reset $1 origin/$(git rev-parse --abbrev-ref HEAD)
}

# cdi: change directory to isl
cdi() {
    cd $ISL/$1
}

# cdd: change directory to deepwave_debug
cdd() {
    cd $DEEPWAVE_DEBUG/$1
}

# cdb: change directory to basher
cdb() {
    cd $BASHER/$1
}

#cdc: change directory to conda prefix
cdc() {
    cd $CONDA_PREFIX/$1
}

# cdr: change directory to repo
cdr() {
    cd $REPO/$1
}

# eplat: edit platform
eplat() {
    efile $BASHER/src/platform/$1
}

# mhr: masthay helpers reinstall -- deprecated -- use pip install -e .
mhr() {
    PREV=$(pwd)
    cdr masthay_helpers
    source reinstall.sh
    cd $PREV
}

# check_devices: check devices
check_devices() {
    python -c "from misfit_toys.utils import check_devices; check_devices('$1')"
}

# cst: "check status" -- repeatedly print contents of file with sleeps
cst() {
    sleep_time=${1:-3}
    iterations=${2:-1000}
    FILE=${3:-"/tmp/debug.out"}
    c1=${4:-magenta}
    c2=${5:-green}
    for ((i = 0; i < iterations; i++)); do
        if ((i % 2 == 0)); then
            cecho --color=$c1 "$(cat $FILE)"
        else
            cecho --color=$c2 "$(cat $FILE)"
        fi
        sleep $sleep_time
    done
}

# phelp: "python help"
phelp() {
    python $BASHER/src/py_scripts/phelp.py $@
}

# gce: "git commit empty"
gce() {
    git commit --allow-empty $@
}

# rcache: remove __pycache__ recursively
rcache() {
    find . -type d -name "__pycache__" -print -exec rm -rf {} \; 2>/dev/null
}

# pcr: "pre-commit run"
pcr() {
    pre-commit clean
    pre-commit install
}

# gds: "git difftool staged"
gds() {
    git difftool --staged @{u}
}

# update_pre_commit: update pre-commit hooks
update_pre_commit() {
    # Check if HOOK_EM environment variable is set
    if [[ -z "${HOOK_EM}" ]]; then
        echo "Error: The HOOK_EM environment variable is not set."
        return 1
    fi

    # Check if REPO environment variable is set
    if [[ -z "${REPO}" ]]; then
        echo "Error: The REPO environment variable is not set."
        return 1
    fi

    # Find all directories in your $REPO variable, excluding any paths that contain $HOOK_EM
    find "${REPO}" -maxdepth 1 -mindepth 1 -type d | grep -v "${HOOK_EM}" | while read -r repo_dir; do
        echo "Updating repository: ${repo_dir}"

        # clean pre-existing directories
        rm -rf "${repo_dir}/.gitlint_rules"

        # Copy the pre-commit config files into the repository
        cp "${HOOK_EM}/.pre-commit-config.yaml" "${repo_dir}/"
        cp "${HOOK_EM}/.gitattributes" "${repo_dir}/"
        cp "${HOOK_EM}/.gitlint" "${repo_dir}/"
        cp -r "${HOOK_EM}/.gitlint_rules" "${repo_dir}/.gitlint_rules"

        # Change directory to the repository
        pushd "${repo_dir}" >/dev/null || return

        # Remove commit-msg
        rm .git/hooks/commit-msg 2>/dev/null 2>&1
        gitlint install-hook

        # Clean the pre-commit environment
        pre-commit clean >/dev/null 2>&1

        # Install the pre-commit hook
        pre-commit install >/dev/null 2>&1

        # Return to the original directory
        popd >/dev/null || return
    done
}

# lsh: "list hidden" -- list ONLY hidden files
lsh() {
    ls -ld .?* | awk '{print $9}' | grep -v '[.][.]'
}

# gca: "git commit amend"
gca() {
    git commit --amend
}

# grt: "git root"
grt() {
    git rev-parse --show-toplevel
}

# sfi: "sort file in place"
sfi() {
    # Check if the file path is provided
    if [ -z "$1" ]; then
        echo "No file path provided."
        return 1
    fi

    local file_path="$1"

    # Check if the file exists
    if [ ! -f "$file_path" ]; then
        echo "File does not exist: $file_path"
        return 1
    fi

    # Sort the file and overwrite it
    sort "$file_path" >"$file_path.sorted"
    mv "$file_path.sorted" "$file_path"
}

# cimp: "check imports" -- create list of all imports and check against requirements.txt
cimp() {
    local temp_file="/tmp/requirements_temp.txt"
    local requirements_file="$(grt)/requirements.txt"
    RES=$(find $(grt) -name "*.py" -exec grep -E "^(import|from)" {} \; | awk '{print $2}' | sed 's/\([^\.]*\)\..*/\1/' | sort | uniq)
    PIP_LIST=$(pip list)

    >"$temp_file" # Empty the file before starting

    for res in $RES; do
        MATCH=$(echo "$PIP_LIST" | grep -w "$res" | awk '{printf "%s>=%s\n", $1, $2}')
        if [[ ! -z "$MATCH" ]]; then
            echo "$MATCH" >>"$temp_file"
        fi
    done

    sfi "$temp_file"
    sfi "$requirements_file"

    git difftool -y "$temp_file" "$requirements_file"
}

# stats: compute stats on a file (csv file?)
stats() {
    python $BASHER/src/py_scripts/stats.py $@
}

# ccsv: "color csv"
ccsv() {
    python $BASHER/src/py_scripts/ccsv.py $@
}

# trich: toggle RICH_LOG
trich() {
    if [ -z $RICH_LOG ]; then
        export RICH_LOG='none'
    else
        unset RICH_LOG
    fi
    echo "RICH_LOG=$RICH_LOG"
}

# sansi: strip all ansi codes
sansi() {
    sed $@ 's/\x1b\[[0-9;]*[mGKFH]//g'
}

# ransi: replace all ansi codes with a marker
ransi() {
    local replace=${1:-"ANSI_MARKER"}
    sed "s/\x1b\[[0-9;]*[mGKFH]/$replace/g"
}

# salpha: strip non-alpha numeric symbols
salpha() {
    sed "$@" 's/[^0-9a-zA-Z .+-]//g'
}

# pip_ver: pip version
pip_ver() {
    pip show $1 2>/dev/null | grep "Version"
}

# my_black: black 80 chars, no string norm, preview, skip magic trailing comma
my_black() {
    black --line-length 80 --skip-string-normalization --preview --skip-magic-trailing-comma $@
}

# esite: edit site customize file
esite() {
    local prev=$(pwd)
    pips
    code sitecustomize.py
    cd $prev
}

# gsrt: "git super root" -- go to the root of the repo, disregarding submodules
gsrt() {
    local super=$(git rev-parse --show-superproject-working-tree)
    if [ -z $super ]; then
        echo "$(git rev-parse --show-toplevel)"
    else
        echo "$super"
    fi
}

# gsmu: git submodule update --recursive --remote
gsmu() {
    git submodule update --recursive --remote
}

# gsync: sync GitHookEm settings
gsync() {
    local prev=$(pwd)
    cd $(gsrt)
    cd GitHookEm
    ./sync.sh
    cd $prev
}

# cdh: cd $HOME/$1
cdh() {
    cd $HOME/$1
}

# ufw_monitor: run ufw_monitor.py
ufw_monitor() {
    sudo $(which python3) $BASHER/src/py_scripts/ufw_monitor.py --basher $BASHER $@
}

# glcf: "git log full"
glcf() {
    git log --graph --decorate --all --format="%C(auto)%h (%ar) %s%d%n%b"
}

# tst: Run pytest in tests directory
tst() {
    # local show_code=${1:-0}
    # local prev=$(pwd)
    # cdi
    # mytest tests $show_code
    # cd $prev
    cdi
    pytest tests
    cd $OLDPWD
}

# gslf: "git show log full"
gslf() {
    local file=$1
    git log --color --pretty=format:"%h - %s" -p -- $file >/tmp/git_log_full.ans
    code /tmp/git_log_full.ans
}

# mytest: monitor pytest, plus pun intended
mytest() {
    local file=${1:-"tests"}
    local show_code=${2:-0}
    pytest $file --color=yes >/tmp/pytest.ans &
    pytest_pid=$!
    if [[ $show_code -eq 1 ]]; then
        code /tmp/pytest.ans
    fi

    # Initialize the counter
    dead_count=0

    while true; do
        sleep 2

        # Find the line numbers for "Captured stderr call" and "short test summary info"
        err_line=$(grep -n "Captured stderr call" /tmp/pytest.ans | head -n 1 | cut -d: -f1)
        sum_line=$(grep -n "short test summary info" /tmp/pytest.ans | head -n 1 | cut -d: -f1)

        # Check if both markers are found
        if [[ -n "$err_line" && -n "$sum_line" && $sum_line -gt $err_line ]]; then
            # Delete lines from err_line to sum_line, excluding sum_line
            sed -i "${err_line},$(($sum_line - 1))d" /tmp/pytest.ans
            break
        fi

        # Check if pytest is still running
        if ! kill -0 $pytest_pid 2>/dev/null; then
            ((dead_count++))
            if [[ $dead_count -ge 3 ]]; then
                # echo "pytest process has finished. Exiting..."
                clear
                cat /tmp/pytest.ans
                break
            fi
        else
            # Reset dead count if pytest is still running
            dead_count=0
        fi
        clear
        cat /tmp/pytest.ans
    done
}

# sclr: "string color" -- ctxt -l "$1" -c $1
sclr() {
    ctxt -l "$1" -c $1
}

# code_blender: open blender in vscode
code_blender() {
    sudo /usr/bin/blender --python /home/tyler/.vscode/extensions/jacqueslucke.blender-development-0.0.18/pythonFiles/launch.py
}

# link_addons: link blender addons
link_addons() {
    ln -s $ADDON_PATH/$ADDON_HELPERS_NAME.py $(pwd)/$ADDON_HELPERS_NAME.py
}

# cdo: "change directory old"
cdo() {
    cd $OLDPWD
}

# gci: "git clean interactive"
gci() {
    git clean -i
}

# cmts: "count comments" -- count the number of comments in a file
cmts() {
    local file=$1
    local num_cmts=${2:-5}
    if [[ $(cat $file | sed 's/.*#.*/#/' | sed 's/^\([#]*\).*/\1/' | tr '\n' '@' | sed 's/#@/#/g' | tr '@' ' ' | grep $(perl -E "say '#' x $num_cmts") | wc -l) -eq 1 ]]; then
        echo "$file"
    fi
}

# cmta: "count comments all" -- count the number of comments in all files
cmta() {
    local dir=${1:-.}
    local num_cmts=${2:-5}
    find $dir -type f -name "*.py" | while read file; do
        cmts $file $num_cmts
    done
}

# see_torch: see torch directory
see_torch() {
    local make_figs=${1:-"False"}
    local cmd="from masthay_helpers.global_helpers import torch_dir_see"
    cmd="$cmd; torch_dir_see(make_figs=$make_figs)"
    python -c "$cmd"
}

# rhome: replace home with ~
rhome() {
    echo "$1" | sed "s|$HOME|~|g"
}

# gbt: "git branch type"
gbt() {
    local category=${1:-"deleted: "}
    local res=$(gsl | grep "$category" | awk -F':' '{print $2}' | tail -n 1 | xargs)
    echo $res
}

# rgrm: "retroactive git remove"
rgrm() {
    local res=$(gbt $1)
    while $res; do
        if [[ -z "$res" ]]; then
            break
        fi
        git rm --cached $res
        res=$(gsl | grep "$category" | awk -F':' '{print $2}' | tail -n 1 | xargs)
    done
}

# update_content: update content based on build and target directories
#    Typical use case is for latex resume/cover letter build pdf version control
update_content() {
    local build_dir=$1
    local target_dir=$2
    local build_file=${3:-"main.pdf"}
    local target_base=${4:-"TylerMasthay_Resume"}
    local target_name=${5:-""}

    # Check if either build directory exists; if not exit
    if [[ ! -d "$build_dir" ]]; then
        echo "Build directory does not exist: $build_dir"
        return 1
    elif
        [[ ! -d "$target_dir" ]]
    then
        echo "Target directory does not exist: $target_dir"
        return 1
    elif
        [[ ! -f "$build_dir/$build_file" ]]
    then
        echo "Build file does not exist: $build_dir/$build_file"
        return 1
    fi

    local ext=".pdf"
    build_file=${build_file//$ext/}
    build_file="$build_file$ext"
    target_base=${target_base//$ext/}
    target_name=${target_name//$ext/}

    if [[ $target_name == "" ]]; then
        cmd="cp $build_dir/$build_file $target_dir/$target_base$ext"
        echo $cmd
        eval $cmd
        return 0
    fi
    local subdir=${target_name//"_"/"/"}
    local final_dir=${target_dir}/${subdir}
    local final_file_name="${target_base}_${target_name}${ext}"
    final_file_name="$final_dir/$final_file_name"

    local cmd="cp $build_dir/$build_file $final_file_name"
    echo $cmd
    mkdir -p $final_dir
    eval $cmd
}

# update_resume: update_content for resume
update_resume() {
    update_content "$REPO/CV" "$JOBS" "main.pdf" "TylerMasthay_Resume" $1
}

# update_cover_letter: update_content for cover letter
update_cover_letter() {
    update_content "$REPO/CoverLetterHistory" "$JOBS" "main.pdf" "TylerMasthay_CoverLetter" $1
}

# cdj: "change directory job"
cdj() {
    cd $JOBS/$1
}

# update_job: update_content for job posting
update_job() {
    update_resume "$1"
    update_cover_letter "$1"
}

# gss: git show --stat "HEAD~$1"
gss() {
    local commit=${1:-0}
    if [ $commit -eq 0 ]; then
        git show --stat
        return
    else
        git show --stat "HEAD~$commit"
    fi
}

# ghwv: "github workflow view"
ghwv() {
    gh workflow view $@
}

# dsmu: download submodule update -- used for overleaf/github syncing
#     This is necessary because overleaf does not support submodules.
dsmu() {
    local prev=$(pwd)
    local repo_name=${1:-CustomCommands}
    echo $repo_name
    rm -rf $repo_name
    git clone https://github.com/tmasthay/$repo_name.git
    echo "Remember to remove $repo_name/.git"
}

# pyig: "python ignore warnings"
pyig() {
    python -W ignore $@
}

# new_fang: create new fang interview question setup
new_fang() {
    local name=$(pwd | awk -F'/' '{print $NF}')
    cp $REPO/IvoryTowerTests/config_template.yaml $(pwd)/config.yaml
    cp $REPO/IvoryTowerTests/template.py "$(pwd)/$name.py"
    sed -i "s/your_function_name/$name/g" "$(pwd)/$name.py"
}

# protect_file: protect a file from being modified
protect_file() {
    local file=$1
    local permissions=${2:-"644"}
    sudo chattr -i $file
    sudo chown root:root $file
    sudo chmod $permissions $file
    sudo chattr +i $file
    ls -al $file
}

# export_funcs: Export all functions
export_funcs() {
    declare -F | awk '{print $3}' | while read -r func; do
        export -f "$func"
    done
}

# declare_funcs_subshell: Declare all functions in a subshell
declare_funcs_subshell() {
    declare -F | sed ':a;N;$!ba;s/\n/; /g'
}

# link_sitecustomize: Link sitecustomize.py to the current conda env
link_sitecustomize() {
    local run_cmd=${1:-0}
    local cmd="ln -s $BASHER/src/py_scripts/sitecustomize.py $(pips 1)/sitecustomize.py"
    if [[ $run_cmd -eq 0 ]]; then
        echo $cmd
    else
        eval $cmd
    fi
}

# trichl: toggle RICH_LOCALS
trichl() {
    if [ -z $RICH_LOCALS ]; then
        export RICH_LOCALS='true'
    else
        unset RICH_LOCALS
    fi
    echo "RICH_LOCALS=$RICH_LOCALS"
}

# cblender: "custom blender" -- this is the one I use since the system blender is outdated
cblender() {
    /home/tyler/Software/blender-4.1.0-linux-x64/blender
}

# dcmd: "desktop command" -- find and display desktop commands
dcmd() {
    ctxt -l "GNOME RESULTS for $1" -c red
    find /usr/share/applications -type f -name "*$1*.desktop" -exec grep -Ho "Exec=.*" {} \; | awk -F'Exec=' '{print "    " $2}'
    echo ""
    ctxt -l "SNAP RESULTS for $1" -c red
    find /var/lib/snapd/desktop/applications -type f -name "*$1*.desktop" -exec grep -Ho "Exec=.*" {} \; | awk -F'Exec=' '{print "    " $2}'
}

# undo_conda: undo conda environment -- weird bug on home machine
undo_conda() {
    cdct
    cdct
    cact base
    cact dw
}

pc() {
    python $BASHER/src/py_scripts/$1.py "${@:2}"
}

pce() {
    eval $(pc $@)
}

epy() {
    local script_path="$BASHER/src/py_scripts/$1.py"

    if command -v code >/dev/null 2>&1; then
        # If VS Code's 'code' command is available, use it
        code "$script_path"
    else
        # Otherwise, fall back to using Vim
        vim "$script_path"
    fi
}

cd() {
    builtin cd "$@" && echo $(pwd) >>~/.cd_history
    local history=$(cat ~/.cd_history | tail -n 100)
    echo "$history" >~/.cd_history
}

cdh() {
    local num_see=${1:-10}
    cat ~/.cd_history | tail -n $num_see
}

pywest() {
    pytest -p no:warnings --color=yes $@
}

cdmh() {
    cdr masthay_helpers
}

gcnv() {
    git commit --no-verify $@
}

genv() {
    gau
    gcnv $@
    gp
}

kgpy() {
    nvidia-smi | grep "python" | awk '{print $5}' | xargs kill -9
}

tpt() {
    cd $BASHER/src/py_scripts
    python tpt.py $@
    cd $OLDPWD
}

cda() {
    local FURTHER=${1:-""}
    cd $ISL/misfit_toys/examples/hydra/$FURTHER
}

fcode() {
    /home/tyler/.local/share/flatpak/exports/bin/com.visualstudio.code $@
}

lt() {
    tree -I "__*" $@
}

ch() {
    pyig $@ --help | pc chydra
}

rch() {
    pyig $@ --help | pc chydra rand
}

my_flake() {
    flake8 --extend-ignore=F401,F403,F405,E501,E203
}

chlist() {
    cp $REPO/Experiments/organization/$1.yaml .
    code $1.yaml
}

create_gifs() {
    local delay=100     # Default delay (100 = 1 second)
    local interactive=0 # Non-interactive by default
    local remove_jpgs=0 # Do not remove JPGs by default

    # Reset OPTIND to 1 in case the function is called multiple times in the same shell session
    OPTIND=1

    # Process options
    while getopts "ir" opt; do
        case ${opt} in
        i) interactive=1 ;;
        r) remove_jpgs=1 ;;
        \?)
            echo "Invalid option: -$OPTARG" >&2
            echo "Usage: create_gifs [-i] [-r]" >&2
            return 1
            ;;
        esac
    done

    shift $((OPTIND - 1)) # Shift off the options and optional --

    # Ask for custom delay if in interactive mode
    if [[ $interactive -eq 1 ]]; then
        read -p "Enter delay between frames (in hundredths of a second, 100 = 1s): " input_delay
        if [[ ! -z "$input_delay" && "$input_delay" =~ ^[0-9]+$ ]]; then
            delay=$input_delay
        else
            echo "Invalid input. Using default delay."
        fi
    fi

    # Extract unique prefixes from the filenames
    prefixes=$(ls *.jpg 2>/dev/null | awk -F'_' '{print $1}' | uniq)

    if [ -z "$prefixes" ]; then
        echo "No JPG files found."
        return 1
    fi

    for prefix in $prefixes; do
        local proceed="y"
        if [[ $interactive -eq 1 ]]; then
            read -p "Create GIF for '$prefix' images? (y/n): " proceed
        fi

        if [[ "$proceed" == "y" ]]; then
            # Create a GIF for each type of image, with the specified delay between frames
            convert -delay $delay ${prefix}_*.jpg ${prefix}.gif
            echo "GIF created: ${prefix}.gif"
        fi
    done

    # Handle removal of JPGs if -r option is provided
    if [[ $remove_jpgs -eq 1 ]]; then
        if [[ $interactive -eq 1 ]]; then
            read -p "Remove all JPG files? (y/n): " confirm_remove
            if [[ "$confirm_remove" == "y" ]]; then
                echo "Removing JPG files..."
                rm -f *.jpg
                echo "JPG files removed."
            else
                echo "JPG files retained."
            fi
        else
            echo "Removing JPG files..."
            rm -f *.jpg
            echo "JPG files removed."
        fi
    fi
}

lres() {
    local further=${1:-"beta/loss/figs"}
    cd /home/tyler/Documents/repos/IslandOfMisfitToys/tests/outputs
    cd $(ls -t | head -n 1)
    cd $(ls -t | head -n 1)
    cd $further
}

cdg() {
    local git_root=$(git rev-parse --show-toplevel)
    local path=${1:-""}

    local workflows_alias="wkf"
    local workflows_dir=".github/workflows"

    if [[ $path == "$workflows_alias" ]]; then
        path=$workflows_dir
    fi

    cd "$git_root/$path"
}

# sss: Screenshot sync
sss() {
    local num_sync=${1:-1}
    local oldpwd=$(pwd)
    local screenshot_path="$HOME/Pictures/Screenshots"
    local icloud_path="$screenshot_path/icloud"

    cd $screenshot_path
    local png_files_in_order

    # Determine how many files to sync based on num_sync
    if [[ $num_sync != "all" && $num_sync != "a" ]]; then
        echo "num_sync=$num_sync"
        png_files_in_order=$(ls -t | grep ".png" | head -n $num_sync)
    else
        echo "num_sync=all"
        png_files_in_order=$(ls -t | grep ".png")
    fi
    echo "png_files_in_order=$png_files_in_order"

    #check number of pre-existing files in $icloud_path
    mkdir -p $icloud_path
    local start_idx=$(ls $icloud_path | wc -l)

    # Convert png files to array properly handling spaces in filenames
    local png_files_array=()
    while IFS= read -r line; do
        png_files_array+=("$line")
    done <<<"$png_files_in_order"

    #convert them all to jpg files with the same name in $icloud_path
    for file in "${png_files_array[@]}"; do
        echo "file=$file"
        local curr_idx=$((start_idx + 1))
        convert "$file" "$icloud_path/$curr_idx.jpg"
        start_idx=$curr_idx # Update start_idx so that each file gets a unique index
    done
    cd $oldpwd
}

# ksg: "kill stray gpu"
ksg() {
    kill $(nvidia-smi | grep "dw/bin" | awk '{print $5}')
}

# cdrec: "cd most recent"
cdrec() {
    depth=${1:-1}
    cd $(ls -t | head -n $depth | tail -n 1)
}

# glo: git log oneline
glo() {
    git log --oneline
}

# gcmp: git compare
# Helper function to echo the comparison result
compare_message() {
    local type=$1 # "local" or "remote"
    local ahead=$2
    local behind=$3
    local branch=$4
    local message=""

    message="${type^}"
    if [ "$ahead" -eq 0 ] && [ "$behind" -eq 0 ]; then
        message+="Up to date with ${branch}."
    else
        [ "$ahead" -ne 0 ] && message+="$ahead commits ahead of"
        [ "$ahead" -ne 0 ] && [ "$behind" -ne 0 ] && message+=", "
        [ "$behind" -ne 0 ] && message+="$behind commits behind"
        message+=" ${branch}."
    fi
    echo $message
}

gcmp_lcl() {
    local branch=${1:-main}
    local ahead=$(git rev-list --count --right-only $branch...HEAD)
    local behind=$(git rev-list --count --left-only $branch...HEAD)
    compare_message "LOCAL:  " $ahead $behind $branch
}

gcmp_remote() {
    local branch=${1:-main}
    if git show-ref --verify --quiet refs/remotes/origin/$branch; then
        local ahead=$(git rev-list --count --left-only @{upstream}...origin/$branch)
        local behind=$(git rev-list --count --right-only @{upstream}...origin/$branch)
        compare_message "REMOTE: " $ahead $behind "origin/$branch"
    else
        echo "No remote branch named origin/$branch."
    fi
}

gcmp() {
    local branch=${1:-main}
    gcmp_lcl $branch
    gcmp_remote $branch
}

# mrf: "most recent files"
# mrf() {
#     local starting_path="${1:-$(pwd)}" # Default to current working directory's absolute path
#     local mindepth="${2:-1}"           # Minimum depth for find; default to 1
#     local maxdepth="${3:-5}"           # Maximum depth for find; default to 5
#     local file_count="${4:-5}"         # Number of files to display; default to 5

#     # Find files, execute stat for modification times, sort them, and display the last N files
#     find "$starting_path" -mindepth "$mindepth" -maxdepth "$maxdepth" -type f -exec stat --format='%y %n' {} + | sort | tail -n "$file_count"
# }

# To use this function, source your .bashrc after adding it or just declare it in your current terminal session.

# You can now use this function by calling it from your shell like this:
# find_modified_files [path] [mindepth] [maxdepth] [number of files]

# esk: "easy ssh key"
esk() {
    cd ~/.ssh
    ssh-keygen -t ed25519 -b 4096 -N "" -f id_$1
    cd $OLDPWD
}

# my_black: custom black config
my_black() {
    black --line-length 80 --skip-string-normalization --preview --skip-magic-trailing-comma $@
}

sgp() {
    gpaste-client | grep "$1" | awk '{print $2}'
}

trc() {
    local first_arg=$1

    # if first_arg = -cc, then don't use defaults, else use defaults
    if [ "$first_arg" == "-cc" ]; then
        shift
        tree $@ | pc tclr
    else
        treee -I "__*" -C --dirs-first $@ | pc tclr
    fi
}
echo "ignore this" >/dev/null

source ~/.platform/functions
